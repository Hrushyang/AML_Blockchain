{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kAZL388ADqqw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.offline as py \n",
    "import plotly.graph_objs as go \n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "q17sC0FRD9TB"
   },
   "outputs": [],
   "source": [
    "edges = pd.read_csv(\"Dataset/elliptic_txs_edgelist.csv\")\n",
    "features = pd.read_csv(\"Dataset/elliptic_txs_features.csv\",header=None)\n",
    "classes = pd.read_csv(\"Dataset/elliptic_txs_classes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0MfXlVAAEAHI"
   },
   "outputs": [],
   "source": [
    "tx_features = [\"tx_feat_\"+str(i) for i in range(2,95)]\n",
    "agg_features = [\"agg_feat_\"+str(i) for i in range(1,73)]\n",
    "features.columns = [\"txId\",\"time_step\"] + tx_features + agg_features\n",
    "features = pd.merge(features,classes,left_on=\"txId\",right_on=\"txId\",how='left')\n",
    "features['class'] = features['class'].apply(lambda x: '0' if x == \"unknown\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JJ8OC72nECcl"
   },
   "outputs": [],
   "source": [
    "count_by_class = features[[\"time_step\",'class']].groupby(['time_step','class']).size().to_frame().reset_index()\n",
    "illicit_count = count_by_class[count_by_class['class'] == '1']\n",
    "licit_count = count_by_class[count_by_class['class'] == '2']\n",
    "unknown_count = count_by_class[count_by_class['class'] == \"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SVgrjWpQEFYh"
   },
   "outputs": [],
   "source": [
    "data = features[(features['class']=='1') | (features['class']=='2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LXfT0J4EEH5m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression-All features\n",
      "Precision:0.454 \n",
      "Recall:0.633 \n",
      "F1 Score:0.529\n",
      "Micro-Average F1 Score: 0.928990694345025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data[tx_features+agg_features]\n",
    "y = data['class']\n",
    "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42,shuffle=False)\n",
    "reg = LogisticRegression().fit(X_train,y_train)\n",
    "preds = reg.predict(X_test)\n",
    "prec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\n",
    "print(\"Logistic Regression-All features\")\n",
    "print(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\n",
    "micro_f1 = f1_score(y_test,preds,average='micro')\n",
    "print(\"Micro-Average F1 Score:\",micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VOjJj0wtETes"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression-Local features\n",
      "Precision:0.433 \n",
      "Recall:0.654 \n",
      "F1 Score:0.521\n",
      "Micro-Average F1 Score: 0.9244094488188976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = features[(features['class']=='1') | (features['class']=='2')]\n",
    "X = data[tx_features]\n",
    "y = data['class']\n",
    "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42,shuffle=False)\n",
    "reg = LogisticRegression().fit(X_train,y_train)\n",
    "preds = reg.predict(X_test)\n",
    "prec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\n",
    "print(\"Logistic Regression-Local features\")\n",
    "print(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\n",
    "micro_f1 = f1_score(y_test,preds,average='micro')\n",
    "print(\"Micro-Average F1 Score:\",micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "J2-rKfWFEbe-"
   },
   "outputs": [],
   "source": [
    "embed_names = [\"emb_\"+str(i) for i in range(1,51)]\n",
    "embeddings = pd.read_csv('elliptic.emb',delimiter=\" \",skiprows=1,header=None)\n",
    "embeddings.columns = ['txId'] + [\"emb_\"+str(i) for i in range(1,51)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Snf0e7oxEiGt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - All features + node embeddings\n",
      "Precision:0.457 \n",
      "Recall:0.651 \n",
      "F1 Score:0.537\n",
      "Micro-Average F1 Score: 0.929671274081501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = features[(features['class']=='1') | (features['class']=='2')]\n",
    "data = pd.merge(data,embeddings,how='inner')\n",
    "X = data[tx_features+agg_features+embed_names]\n",
    "y = data['class']\n",
    "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42,shuffle=False)\n",
    "reg = LogisticRegression().fit(X_train,y_train)\n",
    "preds = reg.predict(X_test)\n",
    "prec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\n",
    "print(\"Logistic Regression - All features + node embeddings\")\n",
    "print(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\n",
    "micro_f1 = f1_score(y_test,preds,average='micro')\n",
    "print(\"Micro-Average F1 Score:\",micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "G2HWohLtEmia"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Local features + node embeddings\n",
      "Precision:0.478 \n",
      "Recall:0.653 \n",
      "F1 Score:0.552\n",
      "Micro-Average F1 Score: 0.9335386378285468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = features[(features['class']=='1') | (features['class']=='2')]\n",
    "data = pd.merge(data,embeddings,how='inner')\n",
    "X = data[tx_features+embed_names]\n",
    "y = data['class']\n",
    "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42,shuffle=False)\n",
    "reg = LogisticRegression().fit(X_train,y_train)\n",
    "preds = reg.predict(X_test)\n",
    "prec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\n",
    "print(\"Logistic Regression - Local features + node embeddings\")\n",
    "print(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\n",
    "micro_f1 = f1_score(y_test,preds,average='micro')\n",
    "print(\"Micro-Average F1 Score:\",micro_f1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
