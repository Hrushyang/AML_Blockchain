{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.offline as py \n",
    "import plotly.graph_objs as go \n",
    "py.init_notebook_mode(connected=True)\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.read_csv(\"Dataset/elliptic_txs_edgelist.csv\")\n",
    "features = pd.read_csv(\"Dataset/elliptic_txs_features.csv\",header=None)\n",
    "classes = pd.read_csv(\"Dataset/elliptic_txs_classes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_features = [\"tx_feat_\"+str(i) for i in range(2,95)]\n",
    "agg_features = [\"agg_feat_\"+str(i) for i in range(1,73)]\n",
    "features.columns = [\"txId\",\"time_step\"] + tx_features + agg_features\n",
    "features = pd.merge(features,classes,left_on=\"txId\",right_on=\"txId\",how='left')\n",
    "features['class'] = features['class'].apply(lambda x: '0' if x == \"unknown\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_class = features[[\"time_step\",'class']].groupby(['time_step','class']).size().to_frame().reset_index()\n",
    "illicit_count = count_by_class[count_by_class['class'] == '1']\n",
    "licit_count = count_by_class[count_by_class['class'] == '2']\n",
    "unknown_count = count_by_class[count_by_class['class'] == \"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = features[(features['class']=='1') | (features['class']=='2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[tx_features+agg_features]\n",
    "y = data['class']\n",
    "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=15,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier- All features\n",
      "Precision:0.982 \n",
      "Recall:0.617 \n",
      "F1 Score:0.758\n",
      "Micro-Average F1 Score: 0.9751610594130279\n"
     ]
    }
   ],
   "source": [
    "# Train an XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=50, max_depth=100, random_state=15)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set and evaluate the performance\n",
    "preds = xgb_model.predict(X_test)\n",
    "prec, rec, f1, num = precision_recall_fscore_support(y_test, preds, average=None)\n",
    "print(\"XGBoost Classifier- All features\")\n",
    "print(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\" % (prec[1], rec[1], f1[1]))\n",
    "micro_f1 = f1_score(y_test, preds, average='micro')\n",
    "print(\"Micro-Average F1 Score:\", micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[tx_features]\n",
    "y = data['class']\n",
    "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=15,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier- Local features\n",
      "Precision:0.929 \n",
      "Recall:0.592 \n",
      "F1 Score:0.723\n",
      "Micro-Average F1 Score: 0.9714387974230494\n"
     ]
    }
   ],
   "source": [
    "# Train an XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=50, max_depth=100, random_state=15)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set and evaluate the performance\n",
    "preds = xgb_model.predict(X_test)\n",
    "prec, rec, f1, num = precision_recall_fscore_support(y_test, preds, average=None)\n",
    "print(\"XGBoost Classifier- Local features\")\n",
    "print(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\n",
    "micro_f1 = f1_score(y_test,preds,average='micro')\n",
    "print(\"Micro-Average F1 Score:\",micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_names = [\"emb_\"+str(i) for i in range(1,51)]\n",
    "embeddings = pd.read_csv('elliptic.emb',delimiter=\" \",skiprows=1,header=None)\n",
    "embeddings.columns = ['txId'] + [\"emb_\"+str(i) for i in range(1,51)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = features[(features['class']=='1') | (features['class']=='2')]\n",
    "data = pd.merge(data,embeddings,how='inner')\n",
    "X = data[tx_features+agg_features+embed_names]\n",
    "y = data['class']\n",
    "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=15,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier - All features and node embeddings\n",
      "Precision:0.982 \n",
      "Recall:0.613 \n",
      "F1 Score:0.755\n",
      "Micro-Average F1 Score: 0.9750053713385376\n"
     ]
    }
   ],
   "source": [
    "# Train an XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=50, max_depth=100, random_state=15)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set and evaluate the performance\n",
    "preds = xgb_model.predict(X_test)\n",
    "prec, rec, f1, num = precision_recall_fscore_support(y_test, preds, average=None)\n",
    "print(\"XGBoost Classifier - All features and node embeddings\")\n",
    "print(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\n",
    "micro_f1 = f1_score(y_test,preds,average='micro')\n",
    "print(\"Micro-Average F1 Score:\",micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = features[(features['class']=='1') | (features['class']=='2')]\n",
    "data = pd.merge(data,embeddings,how='inner')\n",
    "X = data[tx_features+embed_names]\n",
    "y = data['class']\n",
    "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=15,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier - Local features and node embeddings\n",
      "Precision:0.937 \n",
      "Recall:0.598 \n",
      "F1 Score:0.730\n",
      "Micro-Average F1 Score: 0.972283893146172\n"
     ]
    }
   ],
   "source": [
    "# Train an XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=50, max_depth=100, random_state=15)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set and evaluate the performance\n",
    "preds = xgb_model.predict(X_test)\n",
    "prec, rec, f1, num = precision_recall_fscore_support(y_test, preds, average=None)\n",
    "\n",
    "print(\"XGBoost Classifier - Local features and node embeddings\")\n",
    "print(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\n",
    "micro_f1 = f1_score(y_test,preds,average='micro')\n",
    "print(\"Micro-Average F1 Score:\",micro_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
